---
title: "psychometrics hw2"
author: "Ryan Louie"
date: "`r format(Sys.Date())`"
output: github_document
---

## Some Helpful Tips on R Notebooks

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

## Load and Describe the Data

```{r}
library(psych)
datafilename<- "http://personality-project.org/r/datasets/psychometrics.prob2.txt"
dataset <- read.table(datafilename, header=TRUE)
describe(dataset)
```

#![Description of Variables](figs/gredata.png)

## GRE Verbal vs Quantitative

```{r}
plot(dataset$GREV ~ dataset$GREQ, xlim=c(191.0, 914.0), ylim=c(138.0, 873.0), xlab="gre quant", ylab="gre verbal")
```

## Correlation Matrix of All Variables

```{r}
round(cor(dataset, use="pairwise"),2)  # cor from stats, lowerCor(dataset) from psycho would give same thing
```

## Scatter Plot of All Variables

```{r}
pairs.panels(dataset[-1], pch=".", gap=0)
```

## Multiple Regression of GREV and GREQ predicting MA

[Helpful link on Interpretation of the LM output](https://stats.stackexchange.com/questions/5135/interpretation-of-rs-lm-output)

- 5 point summary of Residuals Checks out (0 median, 1Q and 3Q are same value)
- Estimates are the mean of the distribution of the Gaussian normal random variable -- our coefficients in the model
- t values are Estimates (betas) divided by Std. Errors.
- The F is the ratio of two variances (SSR/SSE), the variance explained by the parameters in the model (sum of squares of regression, SSR) and the residual or unexplained variance (sum of squares of error, SSE). 

```{r}
fit1 <- lm(MA ~ GREV + GREQ, data = dataset)
summary(fit1)
```

## Multiple R with GREV, GREQ, GREA
```{r}
fit2 <- lm(MA ~ GREV + GREQ + GREA, data = dataset)
summary(fit2)
```

## Compare these two models

[Helpful Stackexchange Link](https://stats.stackexchange.com/questions/53312/comparing-two-models-using-anova-function-in-r)

We are using a One-Way Anova because we have one indep var (MA)
Res.DF =  Residual Degress of Freedom
RSS = Residual Sum of Squares
For all but the first model, the change in degrees of freedom (1) and sum of squares (24) is also given.
Normally the F statistic is most appropriate, which compares the mean square for a row to the residual sum of squares for the largest model considered.

[What is an F statistic link](http://www.statisticshowto.com/probability-and-statistics/f-statistic-value-test/)

Model 2 is "better" since it provides less residual sum of squares.

```{r}
anova(fit1, fit2)
```

## Multiple Dependent Variables

```{r}
R <- lowerCor(dataset[-1])
set.cor(x=1:5, y=6:8, data = R)
```

